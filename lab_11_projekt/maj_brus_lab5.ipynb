{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0f2d52b-4a81-4316-92f0-dc5c08b585c2",
   "metadata": {
    "id": "c0f2d52b-4a81-4316-92f0-dc5c08b585c2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_8/8qs28kr50_v5rng3_4jhcdfr0000gn/T/ipykernel_41227/309872129.py:11: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg', 'pdf') # For export\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgb\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.reset_orig()\n",
    "sns.set()\n",
    "\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "# Torchvision\n",
    "import torchvision\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93551f90-0c6d-48fe-91e8-0ce9487c791f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "93551f90-0c6d-48fe-91e8-0ce9487c791f",
    "outputId": "a14ba3ab-a960-489d-b387-2c509cdd8859",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5daaf9af-8441-4689-ba02-fc033314a31b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5daaf9af-8441-4689-ba02-fc033314a31b",
    "outputId": "ac41a940-fb91-4c9e-e1eb-8a915ee78a41",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Transformations applied on each image => only make them a tensor\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Loading the training dataset. We need to split it into a training and validation part\n",
    "complete_set = torchvision.datasets.ImageFolder(\"trafic_32\", transform=transform)\n",
    "\n",
    "train_size = int(0.84 * len(complete_set))\n",
    "test_size = len(complete_set) - train_size\n",
    "train_set, test_set = data.dataset.random_split(complete_set, [train_size, test_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# We define a set of data loaders that we can use for various purposes later.\n",
    "train_loader = data.DataLoader(train_set, batch_size=1000, shuffle=True, drop_last=True, pin_memory=True, num_workers=2)\n",
    "test_loader = data.DataLoader(test_set, batch_size=1000, shuffle=False, drop_last=True, num_workers=2)\n",
    "\n",
    "def get_train_images(num):\n",
    "    return torch.stack([test_set[i][0] for i in range(10,10+num)], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f7dab0d-2a32-4bc4-88d4-bea53db6b4de",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3f7dab0d-2a32-4bc4-88d4-bea53db6b4de",
    "outputId": "9db88774-f537-40d4-d2fe-339d713da2a6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32935\n",
      "2\n",
      "3\n",
      "32\n",
      "32\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set))\n",
    "print(len(train_set[0]))\n",
    "print(len(train_set[0][0]))\n",
    "print(len(train_set[0][0][0]))\n",
    "print(len(train_set[0][0][0][0]))\n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "835af859-6fde-49c6-a6cc-cb27548783d6",
   "metadata": {
    "id": "835af859-6fde-49c6-a6cc-cb27548783d6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.fc_1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc_2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc_mean  = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_var   = nn.Linear (hidden_dim, latent_dim)\n",
    "        \n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "        \n",
    "        self.training = True\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x       = self.LeakyReLU(self.fc_1(x))\n",
    "        x       = self.LeakyReLU(self.fc_2(x))\n",
    "        mean     = self.fc_mean(x)\n",
    "        log_var  = self.fc_var(x)                      # encoder produces mean and log of variance \n",
    "                                                       #             (i.e., parateters of simple tractable normal distribution \"q\"\n",
    "        \n",
    "        return mean, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3db214fa-fb59-4bc1-a42f-bc1953c46dd3",
   "metadata": {
    "id": "3db214fa-fb59-4bc1-a42f-bc1953c46dd3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc_1 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc_2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc_3 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(x.size())\n",
    "        h     = self.LeakyReLU(self.fc_1(x))\n",
    "        #print(h.size())\n",
    "        h     = self.LeakyReLU(self.fc_2(h))\n",
    "        #print(h.size())\n",
    "        x_hat = torch.sigmoid(self.fc_3(h))\n",
    "        #print(x_hat.size())\n",
    "        x_hat = x_hat.view([-1, 3, 32, 32])\n",
    "        #print(x_hat.size())\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f3d1d5e-5f1a-4d70-97d5-677d720cc416",
   "metadata": {
    "id": "0f3d1d5e-5f1a-4d70-97d5-677d720cc416",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_dim, hidden_dim, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = Encoder(input_dim=x_dim, hidden_dim=hidden_dim, latent_dim=latent_dim)\n",
    "        self.decoder = Decoder(latent_dim=latent_dim, hidden_dim = hidden_dim, output_dim = x_dim)\n",
    "\n",
    "        \n",
    "    def reparameterization(self, mean, var):\n",
    "        z = torch.rand_like(mean) * torch.sqrt(var) + mean\n",
    "        return z\n",
    "        \n",
    "                \n",
    "    def forward(self, x):\n",
    "        mean, log_var = self.encoder(x)\n",
    "        z = self.reparameterization(mean, torch.exp(0.5 * log_var)) # takes exponential function (log var -> var)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat, mean, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "wsDt3eixVrOn",
   "metadata": {
    "id": "wsDt3eixVrOn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def vae_loss_function(x,x_hat,mean,log_var):\n",
    "    reproduction_loss = nn.functional.mse_loss(x_hat,x,reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1+log_var - mean.pow(2) - log_var.exp())\n",
    "    return reproduction_loss + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b87e814-89cb-4c94-931c-77055289496f",
   "metadata": {
    "id": "6b87e814-89cb-4c94-931c-77055289496f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vae = VAE(latent_dim=32, hidden_dim=1000, x_dim=3072).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ddfed56-8b54-41d4-ac43-9baf6968db6f",
   "metadata": {
    "id": "2ddfed56-8b54-41d4-ac43-9baf6968db6f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(vae.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "698f2163-9c75-4db3-86a6-c2207c3e57cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "698f2163-9c75-4db3-86a6-c2207c3e57cd",
    "outputId": "d712c55c-8aea-4e3b-82d7-c2218eff7275",
    "scrolled": true,
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [19], line 14\u001B[0m\n\u001B[1;32m     12\u001B[0m     L1_list \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m#     if n % 10 == 0:\u001B[39;00m\n\u001B[0;32m---> 14\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m x, _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28miter\u001B[39m(test_loader):\n\u001B[1;32m     15\u001B[0m         x  \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     16\u001B[0m         out, _, _ \u001B[38;5;241m=\u001B[39m vae(x)\n",
      "File \u001B[0;32m~/.conda/envs/ssne/lib/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    625\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    626\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    627\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 628\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    629\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    631\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    632\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/.conda/envs/ssne/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1305\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1302\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1303\u001B[0m     \u001B[38;5;66;03m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001B[39;00m\n\u001B[1;32m   1304\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_persistent_workers:\n\u001B[0;32m-> 1305\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_shutdown_workers\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1306\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n\u001B[1;32m   1308\u001B[0m \u001B[38;5;66;03m# Now `self._rcvd_idx` is the batch index we want to fetch\u001B[39;00m\n\u001B[1;32m   1309\u001B[0m \n\u001B[1;32m   1310\u001B[0m \u001B[38;5;66;03m# Check if the next sample has already been generated\u001B[39;00m\n",
      "File \u001B[0;32m~/.conda/envs/ssne/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1430\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._shutdown_workers\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1425\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mark_worker_as_unavailable(worker_id, shutdown\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m   1426\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers:\n\u001B[1;32m   1427\u001B[0m     \u001B[38;5;66;03m# We should be able to join here, but in case anything went\u001B[39;00m\n\u001B[1;32m   1428\u001B[0m     \u001B[38;5;66;03m# wrong, we set a timeout and if the workers fail to join,\u001B[39;00m\n\u001B[1;32m   1429\u001B[0m     \u001B[38;5;66;03m# they are killed in the `finally` block.\u001B[39;00m\n\u001B[0;32m-> 1430\u001B[0m     \u001B[43mw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mMP_STATUS_CHECK_INTERVAL\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1431\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m q \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_queues:\n\u001B[1;32m   1432\u001B[0m     q\u001B[38;5;241m.\u001B[39mcancel_join_thread()\n",
      "File \u001B[0;32m~/.conda/envs/ssne/lib/python3.9/multiprocessing/process.py:149\u001B[0m, in \u001B[0;36mBaseProcess.join\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    147\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parent_pid \u001B[38;5;241m==\u001B[39m os\u001B[38;5;241m.\u001B[39mgetpid(), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcan only join a child process\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    148\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcan only join a started process\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m--> 149\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_popen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    150\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m res \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    151\u001B[0m     _children\u001B[38;5;241m.\u001B[39mdiscard(\u001B[38;5;28mself\u001B[39m)\n",
      "File \u001B[0;32m~/.conda/envs/ssne/lib/python3.9/multiprocessing/popen_fork.py:40\u001B[0m, in \u001B[0;36mPopen.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     39\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmultiprocessing\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconnection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m wait\n\u001B[0;32m---> 40\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msentinel\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m     41\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;66;03m# This shouldn't block if wait() returned successfully.\u001B[39;00m\n",
      "File \u001B[0;32m~/.conda/envs/ssne/lib/python3.9/multiprocessing/connection.py:936\u001B[0m, in \u001B[0;36mwait\u001B[0;34m(object_list, timeout)\u001B[0m\n\u001B[1;32m    933\u001B[0m     deadline \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic() \u001B[38;5;241m+\u001B[39m timeout\n\u001B[1;32m    935\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 936\u001B[0m     ready \u001B[38;5;241m=\u001B[39m \u001B[43mselector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    937\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ready:\n\u001B[1;32m    938\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [key\u001B[38;5;241m.\u001B[39mfileobj \u001B[38;5;28;01mfor\u001B[39;00m (key, events) \u001B[38;5;129;01min\u001B[39;00m ready]\n",
      "File \u001B[0;32m~/.conda/envs/ssne/lib/python3.9/selectors.py:416\u001B[0m, in \u001B[0;36m_PollLikeSelector.select\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    414\u001B[0m ready \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    415\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 416\u001B[0m     fd_event_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_selector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpoll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    417\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mInterruptedError\u001B[39;00m:\n\u001B[1;32m    418\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ready\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "for n in range(num_epochs):\n",
    "    losses_epoch = []\n",
    "    for x, _ in iter(train_loader):\n",
    "        x = x.to(device)\n",
    "        out, means, log_var = vae(x)\n",
    "        loss = vae_loss_function(x, out, means, log_var)\n",
    "        losses_epoch.append(loss.item())\n",
    "        loss.backward()               \n",
    "        optimizer.step()             \n",
    "        optimizer.zero_grad()  \n",
    "    L1_list = []\n",
    "#     if n % 10 == 0:\n",
    "    for x, _ in iter(test_loader):\n",
    "        x  = x.to(device)\n",
    "        out, _, _ = vae(x)\n",
    "        L1_list.append(torch.mean(torch.abs(out-x)).item())\n",
    "    print(f\"Epoch {n} loss {np.mean(np.array(losses_epoch))}, test L1 = {np.mean(L1_list)}\")\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f7ae91-3292-426e-96a2-f793c61b732e",
   "metadata": {
    "id": "62f7ae91-3292-426e-96a2-f793c61b732e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_reconstructions(model, input_imgs, device):\n",
    "    # Reconstruct images\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        reconst_imgs = model.decoder(torch.randn([input_imgs, model.latent_dim]).to(device))\n",
    "    reconst_imgs = reconst_imgs.cpu()\n",
    "    \n",
    "    # Plotting\n",
    "    grid = torchvision.utils.make_grid(imgs, nrow=4, normalize=False, range=(-1,1))\n",
    "    grid = grid.permute(1, 2, 0)\n",
    "    if len(input_imgs) == 4:\n",
    "        plt.figure(figsize=(10,10))\n",
    "    else:\n",
    "        plt.figure(figsize=(600,400))\n",
    "    plt.title(f\"Reconstructions\")\n",
    "    plt.imshow(grid)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    return reconst_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72f9c94-c692-4a68-8f0b-2493b255f8ff",
   "metadata": {
    "scrolled": true,
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_images(model, n_imgs, device):\n",
    "    # Generate images\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        generated_imgs = model.decoder(torch.randn([n_imgs, model.latent_dim]).to(device))\n",
    "    generated_imgs = generated_imgs.cpu()\n",
    "    \n",
    "    grid = torchvision.utils.make_grid(generated_imgs, nrow=4, normalize=False, range=(-1,1))\n",
    "    grid = grid.permute(1, 2, 0)\n",
    "    if len(input_imgs) == 4:\n",
    "        plt.figure(figsize=(10,10))\n",
    "    else:\n",
    "        plt.figure(figsize=(600,400))\n",
    "    plt.title(f\"Generations\")\n",
    "    plt.imshow(grid)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    return generated_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1677a0-6d37-45d2-905c-46f7793fb991",
   "metadata": {
    "scrolled": true,
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reconst_imgs = generate_images(vae, 10, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8a6afc-9e02-4ebb-8ace-fc330f11e3d4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(reconst_imgs.cpu().detach(),\"piatek_brus_maj.pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14409131-a16f-4f7a-a9f6-9db2cc0ec84b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb04637-41f0-4ed7-b589-da1176ef5e27",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaedc3be-3543-45f7-b607-e8bb0506d070",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411e38c8-6216-494a-90db-1137de030e28",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9508c209-7316-40e8-978e-0ce28887ce92",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5955735-f037-487d-81d9-88b58388e901",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c4eeba-9fad-4cfe-902c-0319e9484e3d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "71c4eeba-9fad-4cfe-902c-0319e9484e3d",
    "outputId": "203d420b-9cbe-4435-917d-ad14efde75ca",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_imgs = get_train_images(1000)\n",
    "reconst_imgs = visualize_reconstructions(vae, 1000, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gF-e9HbHTz5K",
   "metadata": {
    "id": "gF-e9HbHTz5K",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_images(model, n_imgs, device):\n",
    "    # Reconstruct images\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        reconst_imgs = model.decoder(torch.randn([n_imgs, model.latent_dim]).to(device))\n",
    "    reconst_imgs = reconst_imgs.cpu()\n",
    "    \n",
    "    # Plotting\n",
    "    grid = torchvision.utils.make_grid(reconst_imgs, nrow=4, normalize=False, range=(-1,1))\n",
    "    grid = grid.permute(1, 2, 0)\n",
    "    if len(input_imgs) == 4:\n",
    "        plt.figure(figsize=(10,10))\n",
    "    else:\n",
    "        plt.figure(figsize=(600,400))\n",
    "    plt.title(f\"Reconstructions\")\n",
    "    plt.imshow(grid)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lxNgHmxnT5K8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lxNgHmxnT5K8",
    "outputId": "e9842e94-6922-4fcc-edce-c67f0c5322f0",
    "scrolled": true,
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "generate_images(vae, 1000, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f94b3d9-9946-4ef2-8a7d-28953b9c189b",
   "metadata": {
    "id": "3f94b3d9-9946-4ef2-8a7d-28953b9c189b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(reconst_imgs.cpu().detach(),\"piatek_brus_maj.pt\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "miniprojekt4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}